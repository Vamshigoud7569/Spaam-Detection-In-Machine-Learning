{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pickle\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Email spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>2909.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Subject: re : term papers  please respond to  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>2910.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Subject: re : actions on anjam ' s resignation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>2911.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Subject: india database  jim / wade ,  as you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>2912.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Subject: re : invitation - wharton et events  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>2913.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Subject: moze cie to zainteresuje  vince ,  da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2910 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  spam                                               text\n",
       "0        1.0   1.0  Subject: naturally irresistible your corporate...\n",
       "1        2.0   1.0  Subject: the stock trading gunslinger  fanny i...\n",
       "2        3.0   1.0  Subject: unbelievable new homes made easy  im ...\n",
       "3        4.0   1.0  Subject: 4 color printing special  request add...\n",
       "4        5.0   1.0  Subject: do not have money , get software cds ...\n",
       "...      ...   ...                                                ...\n",
       "2905  2909.0   0.0  Subject: re : term papers  please respond to  ...\n",
       "2906  2910.0   0.0  Subject: re : actions on anjam ' s resignation...\n",
       "2907  2911.0   0.0  Subject: india database  jim / wade ,  as you ...\n",
       "2908  2912.0   0.0  Subject: re : invitation - wharton et events  ...\n",
       "2909  2913.0   0.0  Subject: moze cie to zainteresuje  vince ,  da...\n",
       "\n",
       "[2910 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "train=train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>2909.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Subject: re : term papers  please respond to  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>2910.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Subject: re : actions on anjam ' s resignation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>2911.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Subject: india database  jim / wade ,  as you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>2912.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Subject: re : invitation - wharton et events  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>2913.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Subject: moze cie to zainteresuje  vince ,  da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2908 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  spam                                               text\n",
       "0        1.0   1.0  Subject: naturally irresistible your corporate...\n",
       "1        2.0   1.0  Subject: the stock trading gunslinger  fanny i...\n",
       "2        3.0   1.0  Subject: unbelievable new homes made easy  im ...\n",
       "3        4.0   1.0  Subject: 4 color printing special  request add...\n",
       "4        5.0   1.0  Subject: do not have money , get software cds ...\n",
       "...      ...   ...                                                ...\n",
       "2905  2909.0   0.0  Subject: re : term papers  please respond to  ...\n",
       "2906  2910.0   0.0  Subject: re : actions on anjam ' s resignation...\n",
       "2907  2911.0   0.0  Subject: india database  jim / wade ,  as you ...\n",
       "2908  2912.0   0.0  Subject: re : invitation - wharton et events  ...\n",
       "2909  2913.0   0.0  Subject: moze cie to zainteresuje  vince ,  da...\n",
       "\n",
       "[2908 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['spam'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['spam']=='its termination would not  have such a phenomenal impact on the power situation .  however '].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x=train['text']\n",
    "df_y=train['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2035,)\n",
      "(873,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x,df_y,test_size=0.3, random_state=9)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer= TfidfVectorizer(min_df=1,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tfidf_vectorizer.fit_transform(x_train) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9980343980343981"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf=MultinomialNB()\n",
    "clf.fit(tfidf_train,y_train)\n",
    "clf.score(tfidf_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test = tfidf_vectorizer.transform(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(tfidf_test )\n",
    "val1 = accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       442\n",
      "         1.0       1.00      0.96      0.98       431\n",
      "\n",
      "    accuracy                           0.98       873\n",
      "   macro avg       0.98      0.98      0.98       873\n",
      "weighted avg       0.98      0.98      0.98       873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[440,   2],\n",
       "       [ 17, 414]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(tfidf_test )\n",
    "y_true=y_test\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_true,y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tranform.pickle','wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pickle','wb') as f:\n",
    "    pickle.dump(clf,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'genetic_selection'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-f2257d1598bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgenetic_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGeneticSelectionCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m selectors = GeneticSelectionCV(clf,\n\u001b[0;32m      3\u001b[0m                                   \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                   \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                   \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'genetic_selection'"
     ]
    }
   ],
   "source": [
    "from genetic_selection import GeneticSelectionCV\n",
    "selectors = GeneticSelectionCV(clf,\n",
    "                                  cv=6,\n",
    "                                  verbose=2,\n",
    "                                  scoring=\"accuracy\",\n",
    "                                  max_features=6,\n",
    "                                  n_population=60,\n",
    "                                  crossover_proba=0.6,\n",
    "                                  mutation_proba=0.2,\n",
    "                                  n_generations=50,\n",
    "                                  crossover_independent_proba=0.6,\n",
    "                                  mutation_independent_proba=0.06,\n",
    "                                  tournament_size=4,\n",
    "                                  n_gen_no_change=20,\n",
    "                                  caching=True,\n",
    "                                  n_jobs=-2)\n",
    "selectors = selectors.fit(tfidf_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = selectors.predict(tfidf_test)\n",
    "val1a = (accuracy_score(y_test, predictions)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAndom Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(tfidf_train,y_train)\n",
    "clf.score(tfidf_train,y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(tfidf_test )\n",
    "val2 = accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(tfidf_test )\n",
    "y_true=y_test\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_true,y_pred)\n",
    "f, ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gentenic Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genetic_selection import GeneticSelectionCV\n",
    "selectors = GeneticSelectionCV(clf,\n",
    "                                  cv=6,\n",
    "                                  verbose=2,\n",
    "                                  scoring=\"accuracy\",\n",
    "                                  max_features=6,\n",
    "                                  n_population=60,\n",
    "                                  crossover_proba=0.6,\n",
    "                                  mutation_proba=0.2,\n",
    "                                  n_generations=50,\n",
    "                                  crossover_independent_proba=0.6,\n",
    "                                  mutation_independent_proba=0.06,\n",
    "                                  tournament_size=4,\n",
    "                                  n_gen_no_change=20,\n",
    "                                  caching=True,\n",
    "                                  n_jobs=-2)\n",
    "selectors = selectors.fit(tfidf_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = selectors.predict(tfidf_test)\n",
    "val2a = (accuracy_score(y_test, predictions)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(tfidf_train,y_train)\n",
    "clf.score(tfidf_train,y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(tfidf_test )\n",
    "val3 = accuracy_score(y_pred,y_test)\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(tfidf_test )\n",
    "y_true=y_test\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_true,y_pred)\n",
    "f, ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genetic_selection import GeneticSelectionCV\n",
    "selectors = GeneticSelectionCV(clf,\n",
    "                                  cv=6,\n",
    "                                  verbose=2,\n",
    "                                  scoring=\"accuracy\",\n",
    "                                  max_features=6,\n",
    "                                  n_population=60,\n",
    "                                  crossover_proba=0.6,\n",
    "                                  mutation_proba=0.2,\n",
    "                                  n_generations=50,\n",
    "                                  crossover_independent_proba=0.6,\n",
    "                                  mutation_independent_proba=0.06,\n",
    "                                  tournament_size=4,\n",
    "                                  n_gen_no_change=20,\n",
    "                                  caching=True,\n",
    "                                  n_jobs=-2)\n",
    "selectors = selectors.fit(tfidf_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = selectors.predict(tfidf_test)\n",
    "val3a = (accuracy_score(y_test, predictions)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('Email spam.csv', sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.text\n",
    "y = df.spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting required labels only and encoding\n",
    "\n",
    "review_labels_train = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required tf modules\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "vocab = X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize a text corpus, by turning each text into sequence of integers\n",
    "\n",
    "tokenizer = Tokenizer(num_words=8000,oov_token='OOV')\n",
    "tokenizer.fit_on_texts(vocab)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(tokenizer)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = X_train.values\n",
    "\n",
    "spam_seqs = tokenizer.texts_to_sequences(spam)\n",
    "\n",
    "padded_sequence_train = pad_sequences(spam_seqs, maxlen=200)\n",
    "print(padded_sequence_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(padded_sequence_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_vector_length = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_vector_length,     \n",
    "                                     input_length=200) )\n",
    "model.add(SpatialDropout1D(0.25))\n",
    "model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = model.fit(padded_sequence_train,review_labels_train,\n",
    "                  validation_split=0.2, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = X_test.values\n",
    "\n",
    "spam_seqs = tokenizer.texts_to_sequences(spam)\n",
    "\n",
    "padded_sequence_test = pad_sequences(spam_seqs, maxlen=200)\n",
    "print(padded_sequence_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_lstm = model.evaluate(padded_sequence_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x= trained\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(x.history['loss'], label='Training Loss')\n",
    "plt.plot(x.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(x.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(x.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_vector_length,     \n",
    "                                     input_length=X_train.shape[0]))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained1 = model.fit(padded_sequence_train,review_labels_train,\n",
    "                  validation_split=0.2, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_bilstm = model.evaluate(padded_sequence_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x= trained1\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(x.history['loss'], label='Training Loss')\n",
    "plt.plot(x.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(x.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(x.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid CNN AND LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv1D,MaxPooling1D\n",
    "from keras.layers import LSTM,Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_vector_length,     \n",
    "                                     input_length=X_train.shape[0]))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "filepath=\"weights_best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained2 = model.fit(padded_sequence_train,review_labels_train,\n",
    "                  validation_split=0.2, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_cnn = model.evaluate(padded_sequence_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x= trained2\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(x.history['loss'], label='Training Loss')\n",
    "plt.plot(x.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(x.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(x.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = [val1*100,val2*100,val3*100,val1a,val2a,val3a,acc_lstm[1]*100,acc_bilstm[1]*100,acc_cnn[1]*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make variabel for save the result and to show it\n",
    "classifier = ('Naive Bayes','RF','SVM','GA-NB','GA-RF','GA-SVM','LSTM','BiLSTM','Hybrid')\n",
    "y_pos = np.arange(len(classifier))\n",
    "print(y_pos)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt2\n",
    "plt2.barh(y_pos, score, align='center', alpha=0.5,color='blue')\n",
    "plt2.yticks(y_pos, classifier)\n",
    "plt2.xlabel('Score')\n",
    "plt2.title('Classification Performance')\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
